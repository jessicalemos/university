{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "from keras.models import model_from_yaml\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 9\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cvs_dataset(ficheiro, col_label):\n",
    "    dataset = np.loadtxt(ficheiro, delimiter=\",\")\n",
    "    print('Formato do dataset: ',dataset.shape)\n",
    "    input_attributes= dataset[:,0:col_label]\n",
    "    output_attributes= dataset[:,col_label]\n",
    "    print('Formatodas variáveis de entrada (input variables): ',input_attributes.shape)\n",
    "    print('Formatoda classede saída(output variables): ',output_attributes.shape)\n",
    "    return(input_attributes,output_attributes)\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    model.add(Dense(8, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\"))\n",
    "    return model\n",
    "\n",
    "def print_model(model,fich):\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(model, to_file=fich, show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "def compile_model(model):\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model \n",
    "\n",
    "def fit_model(model,input_attributes,output_attributes):\n",
    "    history = model.fit(input_attributes, output_attributes, validation_split=0.33, epochs=150, batch_size=10, verbose=2)\n",
    "    return history\n",
    "\n",
    "def print_history_accuracy(history):\n",
    "    print(history.history.keys())\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def print_history_loss(history):\n",
    "    print(history.history.keys())\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def model_evaluate(model,input_attributes,output_attributes):\n",
    "    print(\"###########inicio do evaluate###############################\\n\")\n",
    "    scores = model.evaluate(input_attributes, output_attributes)\n",
    "    print(\"\\n metrica: %s: %.2f%%\\n\"% (model.metrics_names[1], scores[1]*100))\n",
    "    \n",
    "def model_print_predictions(model,input_attributes,output_attributes):\n",
    "    previsoes= model.predict(input_attributes) \n",
    "    # arredondar para 0 ou 1 pois pretende-se um output binário\n",
    "    LP=[]\n",
    "    for prev in previsoes:\n",
    "        LP.append(round(prev[0]))\n",
    "    #LP = [round(prev[0]) for prev in previsoes]\n",
    "    for i in range(len(output_attributes)):\n",
    "        print(\" Class:\",output_attributes[i],\" previsão:\",LP[i])\n",
    "        if i>10: break\n",
    "            \n",
    "def ciclo_completo():\n",
    "    (input_attributes, output_attributes) = read_cvs_dataset(\"pima-indians-diabetes.csv\", 8)\n",
    "    model = create_model()\n",
    "    print_model(model,\"model_MLP.png\")\n",
    "    compile_model(model)\n",
    "    history = fit_model(model,input_attributes,output_attributes)\n",
    "    print_history_accuracy(history)\n",
    "    print_history_loss(history)\n",
    "    model_evaluate(model,input_attributes,output_attributes)\n",
    "    model_print_predictions(model,input_attributes,output_attributes)\n",
    "    \n",
    "def save_model_json(model,fich):\n",
    "    model_json = model.to_json()\n",
    "    with open(fich, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "        \n",
    "def save_model_yaml(model,fich):\n",
    "    model_yaml= model.to_yaml()\n",
    "    with open(fich, \"w\") as yaml_file:\n",
    "        yaml_file.write(model_yaml)\n",
    "        \n",
    "def save_weights_hdf5(model,fich):\n",
    "    model.save_weights(fich)\n",
    "    print(\"Saved model to disk\")\n",
    "    \n",
    "def load_model_json(fich):\n",
    "    json_file= open(fich, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    return loaded_model\n",
    "\n",
    "def load_model_yaml(fich):\n",
    "    yaml_file = open(fich, 'r')\n",
    "    loaded_model_yaml = yaml_file.read()\n",
    "    yaml_file.close()\n",
    "    return model_from_yaml(loaded_model_yaml)\n",
    "\n",
    "def load_weights_hdf5(model,fich):\n",
    "    model.load_weights(fich)\n",
    "    print(\"Loaded model from disk\")\n",
    "    \n",
    "def ciclo_ler_dataset_treinar_gravar():\n",
    "    (input_attributes,output_attributes) = read_cvs_dataset(\"pima-indians-diabetes.csv\",8)\n",
    "    model = create_model()\n",
    "    print_model(model,\"model2.png\")\n",
    "    compile_model(model)\n",
    "    history = fit_model(model,input_attributes,output_attributes)\n",
    "    print_history_accuracy(history)\n",
    "    print_history_loss(history)\n",
    "    model_evaluate(model,input_attributes,output_attributes)\n",
    "    save_model_json(model,\"model.json\")\n",
    "    save_weights_hdf5(model,\"model.h5\")\n",
    "    return(input_attributes,output_attributes)\n",
    "\n",
    "def ciclo_ler_modelo_evaluate_usar(input_attributes,output_attributes):\n",
    "    model = load_model_json(\"model.json\")\n",
    "    load_weights_hdf5(model,\"model.h5\")\n",
    "    compile_model(model)\n",
    "    model_evaluate(model,input_attributes,output_attributes)\n",
    "    model_print_predictions(model,input_attributes,output_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato do dataset:  (768, 9)\n",
      "Formatodas variáveis de entrada (input variables):  (768, 8)\n",
      "Formatoda classede saída(output variables):  (768,)\n",
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/150\n",
      " - 1s - loss: 0.6885 - accuracy: 0.5895 - val_loss: 0.6734 - val_accuracy: 0.6732\n",
      "Epoch 2/150\n",
      " - 0s - loss: 0.6738 - accuracy: 0.6401 - val_loss: 0.6581 - val_accuracy: 0.6732\n",
      "Epoch 3/150\n",
      " - 0s - loss: 0.6675 - accuracy: 0.6381 - val_loss: 0.6566 - val_accuracy: 0.6811\n",
      "Epoch 4/150\n",
      " - 0s - loss: 0.6634 - accuracy: 0.6323 - val_loss: 0.6484 - val_accuracy: 0.6811\n",
      "Epoch 5/150\n",
      " - 0s - loss: 0.6567 - accuracy: 0.6459 - val_loss: 0.6468 - val_accuracy: 0.6693\n",
      "Epoch 6/150\n",
      " - 0s - loss: 0.6569 - accuracy: 0.6440 - val_loss: 0.6509 - val_accuracy: 0.6654\n",
      "Epoch 7/150\n",
      " - 0s - loss: 0.6500 - accuracy: 0.6420 - val_loss: 0.6420 - val_accuracy: 0.6732\n",
      "Epoch 8/150\n",
      " - 0s - loss: 0.6462 - accuracy: 0.6459 - val_loss: 0.6405 - val_accuracy: 0.6654\n",
      "Epoch 9/150\n",
      " - 0s - loss: 0.6448 - accuracy: 0.6440 - val_loss: 0.6357 - val_accuracy: 0.6772\n",
      "Epoch 10/150\n",
      " - 0s - loss: 0.6423 - accuracy: 0.6479 - val_loss: 0.6315 - val_accuracy: 0.6772\n",
      "Epoch 11/150\n",
      " - 0s - loss: 0.6371 - accuracy: 0.6537 - val_loss: 0.6299 - val_accuracy: 0.6772\n",
      "Epoch 12/150\n",
      " - 0s - loss: 0.6342 - accuracy: 0.6479 - val_loss: 0.6283 - val_accuracy: 0.6693\n",
      "Epoch 13/150\n",
      " - 0s - loss: 0.6275 - accuracy: 0.6537 - val_loss: 0.6171 - val_accuracy: 0.6772\n",
      "Epoch 14/150\n",
      " - 0s - loss: 0.6255 - accuracy: 0.6498 - val_loss: 0.6192 - val_accuracy: 0.6614\n",
      "Epoch 15/150\n",
      " - 0s - loss: 0.6223 - accuracy: 0.6576 - val_loss: 0.6149 - val_accuracy: 0.6693\n",
      "Epoch 16/150\n",
      " - 0s - loss: 0.6230 - accuracy: 0.6673 - val_loss: 0.6057 - val_accuracy: 0.6772\n",
      "Epoch 17/150\n",
      " - 0s - loss: 0.6194 - accuracy: 0.6673 - val_loss: 0.6039 - val_accuracy: 0.6732\n",
      "Epoch 18/150\n",
      " - 0s - loss: 0.6161 - accuracy: 0.6556 - val_loss: 0.6072 - val_accuracy: 0.6417\n",
      "Epoch 19/150\n",
      " - 0s - loss: 0.6164 - accuracy: 0.6693 - val_loss: 0.5952 - val_accuracy: 0.6772\n",
      "Epoch 20/150\n",
      " - 0s - loss: 0.6110 - accuracy: 0.6673 - val_loss: 0.5957 - val_accuracy: 0.6535\n",
      "Epoch 21/150\n",
      " - 0s - loss: 0.6115 - accuracy: 0.6654 - val_loss: 0.5992 - val_accuracy: 0.6811\n",
      "Epoch 22/150\n",
      " - 0s - loss: 0.6075 - accuracy: 0.6673 - val_loss: 0.5931 - val_accuracy: 0.7087\n",
      "Epoch 23/150\n",
      " - 0s - loss: 0.5997 - accuracy: 0.6868 - val_loss: 0.6061 - val_accuracy: 0.7008\n",
      "Epoch 24/150\n",
      " - 0s - loss: 0.6003 - accuracy: 0.7004 - val_loss: 0.5756 - val_accuracy: 0.7205\n",
      "Epoch 25/150\n",
      " - 0s - loss: 0.6024 - accuracy: 0.6829 - val_loss: 0.5728 - val_accuracy: 0.7008\n",
      "Epoch 26/150\n",
      " - 0s - loss: 0.5921 - accuracy: 0.7043 - val_loss: 0.5711 - val_accuracy: 0.7008\n",
      "Epoch 27/150\n",
      " - 0s - loss: 0.5917 - accuracy: 0.7043 - val_loss: 0.5674 - val_accuracy: 0.7244\n",
      "Epoch 28/150\n",
      " - 0s - loss: 0.5880 - accuracy: 0.7043 - val_loss: 0.5730 - val_accuracy: 0.7283\n",
      "Epoch 29/150\n",
      " - 0s - loss: 0.5891 - accuracy: 0.6965 - val_loss: 0.5687 - val_accuracy: 0.7323\n",
      "Epoch 30/150\n",
      " - 0s - loss: 0.5894 - accuracy: 0.7004 - val_loss: 0.5736 - val_accuracy: 0.7323\n",
      "Epoch 31/150\n",
      " - 0s - loss: 0.5852 - accuracy: 0.6946 - val_loss: 0.5686 - val_accuracy: 0.7087\n",
      "Epoch 32/150\n",
      " - 0s - loss: 0.5880 - accuracy: 0.7004 - val_loss: 0.5733 - val_accuracy: 0.6969\n",
      "Epoch 33/150\n",
      " - 0s - loss: 0.5874 - accuracy: 0.7004 - val_loss: 0.5645 - val_accuracy: 0.7126\n",
      "Epoch 34/150\n",
      " - 0s - loss: 0.5856 - accuracy: 0.7004 - val_loss: 0.5624 - val_accuracy: 0.7165\n",
      "Epoch 35/150\n",
      " - 0s - loss: 0.5798 - accuracy: 0.6965 - val_loss: 0.5833 - val_accuracy: 0.7047\n",
      "Epoch 36/150\n",
      " - 0s - loss: 0.5829 - accuracy: 0.7023 - val_loss: 0.5610 - val_accuracy: 0.7244\n",
      "Epoch 37/150\n",
      " - 0s - loss: 0.5732 - accuracy: 0.7004 - val_loss: 0.5869 - val_accuracy: 0.7126\n",
      "Epoch 38/150\n",
      " - 0s - loss: 0.5879 - accuracy: 0.6946 - val_loss: 0.5606 - val_accuracy: 0.7283\n",
      "Epoch 39/150\n",
      " - 0s - loss: 0.5756 - accuracy: 0.7101 - val_loss: 0.5679 - val_accuracy: 0.7244\n",
      "Epoch 40/150\n",
      " - 0s - loss: 0.5739 - accuracy: 0.7198 - val_loss: 0.5638 - val_accuracy: 0.6969\n",
      "Epoch 41/150\n",
      " - 0s - loss: 0.5760 - accuracy: 0.7140 - val_loss: 0.5598 - val_accuracy: 0.7244\n",
      "Epoch 42/150\n",
      " - 0s - loss: 0.5798 - accuracy: 0.6965 - val_loss: 0.5604 - val_accuracy: 0.7323\n",
      "Epoch 43/150\n",
      " - 0s - loss: 0.5830 - accuracy: 0.6965 - val_loss: 0.5669 - val_accuracy: 0.7244\n",
      "Epoch 44/150\n",
      " - 0s - loss: 0.5764 - accuracy: 0.7082 - val_loss: 0.5599 - val_accuracy: 0.7323\n",
      "Epoch 45/150\n",
      " - 0s - loss: 0.5671 - accuracy: 0.7218 - val_loss: 0.5573 - val_accuracy: 0.7087\n",
      "Epoch 46/150\n",
      " - 0s - loss: 0.5693 - accuracy: 0.7160 - val_loss: 0.5585 - val_accuracy: 0.7126\n",
      "Epoch 47/150\n",
      " - 0s - loss: 0.5744 - accuracy: 0.7043 - val_loss: 0.5584 - val_accuracy: 0.7244\n",
      "Epoch 48/150\n",
      " - 0s - loss: 0.5645 - accuracy: 0.7121 - val_loss: 0.6088 - val_accuracy: 0.7047\n",
      "Epoch 49/150\n",
      " - 0s - loss: 0.5694 - accuracy: 0.7101 - val_loss: 0.5571 - val_accuracy: 0.7205\n",
      "Epoch 50/150\n",
      " - 0s - loss: 0.5647 - accuracy: 0.7160 - val_loss: 0.5954 - val_accuracy: 0.7126\n",
      "Epoch 51/150\n",
      " - 0s - loss: 0.5731 - accuracy: 0.7179 - val_loss: 0.5581 - val_accuracy: 0.7165\n",
      "Epoch 52/150\n",
      " - 0s - loss: 0.5684 - accuracy: 0.7160 - val_loss: 0.5638 - val_accuracy: 0.7244\n",
      "Epoch 53/150\n",
      " - 0s - loss: 0.5678 - accuracy: 0.7023 - val_loss: 0.5698 - val_accuracy: 0.7165\n",
      "Epoch 54/150\n",
      " - 0s - loss: 0.5688 - accuracy: 0.7160 - val_loss: 0.5558 - val_accuracy: 0.7126\n",
      "Epoch 55/150\n",
      " - 0s - loss: 0.5603 - accuracy: 0.7276 - val_loss: 0.5559 - val_accuracy: 0.7047\n",
      "Epoch 56/150\n",
      " - 0s - loss: 0.5619 - accuracy: 0.7179 - val_loss: 0.5540 - val_accuracy: 0.7165\n",
      "Epoch 57/150\n",
      " - 0s - loss: 0.5663 - accuracy: 0.7315 - val_loss: 0.5612 - val_accuracy: 0.7165\n",
      "Epoch 58/150\n",
      " - 0s - loss: 0.5655 - accuracy: 0.7218 - val_loss: 0.5542 - val_accuracy: 0.7205\n",
      "Epoch 59/150\n",
      " - 0s - loss: 0.5585 - accuracy: 0.7218 - val_loss: 0.5542 - val_accuracy: 0.7087\n",
      "Epoch 60/150\n",
      " - 0s - loss: 0.5633 - accuracy: 0.7121 - val_loss: 0.5520 - val_accuracy: 0.7087\n",
      "Epoch 61/150\n",
      " - 0s - loss: 0.5587 - accuracy: 0.7315 - val_loss: 0.5617 - val_accuracy: 0.7165\n",
      "Epoch 62/150\n",
      " - 0s - loss: 0.5570 - accuracy: 0.7218 - val_loss: 0.5939 - val_accuracy: 0.6614\n",
      "Epoch 63/150\n",
      " - 0s - loss: 0.5657 - accuracy: 0.7121 - val_loss: 0.5517 - val_accuracy: 0.7244\n",
      "Epoch 64/150\n",
      " - 0s - loss: 0.5546 - accuracy: 0.7374 - val_loss: 0.5570 - val_accuracy: 0.7047\n",
      "Epoch 65/150\n",
      " - 0s - loss: 0.5576 - accuracy: 0.7432 - val_loss: 0.5499 - val_accuracy: 0.7165\n",
      "Epoch 66/150\n",
      " - 0s - loss: 0.5547 - accuracy: 0.7296 - val_loss: 0.5514 - val_accuracy: 0.7087\n",
      "Epoch 67/150\n",
      " - 0s - loss: 0.5553 - accuracy: 0.7276 - val_loss: 0.5509 - val_accuracy: 0.7323\n",
      "Epoch 68/150\n",
      " - 0s - loss: 0.5632 - accuracy: 0.7257 - val_loss: 0.5501 - val_accuracy: 0.7323\n",
      "Epoch 69/150\n",
      " - 0s - loss: 0.5539 - accuracy: 0.7276 - val_loss: 0.5615 - val_accuracy: 0.7244\n",
      "Epoch 70/150\n",
      " - 0s - loss: 0.5627 - accuracy: 0.7198 - val_loss: 0.5525 - val_accuracy: 0.7244\n",
      "Epoch 71/150\n",
      " - 0s - loss: 0.5541 - accuracy: 0.7412 - val_loss: 0.5480 - val_accuracy: 0.7126\n",
      "Epoch 72/150\n",
      " - 0s - loss: 0.5585 - accuracy: 0.7315 - val_loss: 0.5576 - val_accuracy: 0.7205\n",
      "Epoch 73/150\n",
      " - 0s - loss: 0.5527 - accuracy: 0.7335 - val_loss: 0.5523 - val_accuracy: 0.7244\n",
      "Epoch 74/150\n",
      " - 0s - loss: 0.5528 - accuracy: 0.7315 - val_loss: 0.5591 - val_accuracy: 0.7205\n",
      "Epoch 75/150\n",
      " - 0s - loss: 0.5500 - accuracy: 0.7374 - val_loss: 0.5474 - val_accuracy: 0.7205\n",
      "Epoch 76/150\n",
      " - 0s - loss: 0.5500 - accuracy: 0.7315 - val_loss: 0.5895 - val_accuracy: 0.7205\n",
      "Epoch 77/150\n",
      " - 0s - loss: 0.5532 - accuracy: 0.7335 - val_loss: 0.5566 - val_accuracy: 0.7205\n",
      "Epoch 78/150\n",
      " - 0s - loss: 0.5571 - accuracy: 0.7198 - val_loss: 0.5764 - val_accuracy: 0.7008\n",
      "Epoch 79/150\n",
      " - 0s - loss: 0.5494 - accuracy: 0.7257 - val_loss: 0.5558 - val_accuracy: 0.7244\n",
      "Epoch 80/150\n",
      " - 0s - loss: 0.5509 - accuracy: 0.7335 - val_loss: 0.5649 - val_accuracy: 0.7244\n",
      "Epoch 81/150\n",
      " - 0s - loss: 0.5549 - accuracy: 0.7218 - val_loss: 0.5590 - val_accuracy: 0.7283\n",
      "Epoch 82/150\n",
      " - 0s - loss: 0.5530 - accuracy: 0.7218 - val_loss: 0.5478 - val_accuracy: 0.7362\n",
      "Epoch 83/150\n",
      " - 0s - loss: 0.5467 - accuracy: 0.7393 - val_loss: 0.5477 - val_accuracy: 0.7362\n",
      "Epoch 84/150\n",
      " - 0s - loss: 0.5479 - accuracy: 0.7335 - val_loss: 0.5460 - val_accuracy: 0.7362\n",
      "Epoch 85/150\n",
      " - 0s - loss: 0.5530 - accuracy: 0.7296 - val_loss: 0.5705 - val_accuracy: 0.7205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/150\n",
      " - 0s - loss: 0.5497 - accuracy: 0.7354 - val_loss: 0.5566 - val_accuracy: 0.6969\n",
      "Epoch 87/150\n",
      " - 0s - loss: 0.5710 - accuracy: 0.7160 - val_loss: 0.5543 - val_accuracy: 0.7205\n",
      "Epoch 88/150\n",
      " - 0s - loss: 0.5564 - accuracy: 0.7276 - val_loss: 0.5494 - val_accuracy: 0.7402\n",
      "Epoch 89/150\n",
      " - 0s - loss: 0.5384 - accuracy: 0.7354 - val_loss: 0.5690 - val_accuracy: 0.7087\n",
      "Epoch 90/150\n",
      " - 0s - loss: 0.5519 - accuracy: 0.7315 - val_loss: 0.5395 - val_accuracy: 0.7520\n",
      "Epoch 91/150\n",
      " - 0s - loss: 0.5452 - accuracy: 0.7451 - val_loss: 0.5430 - val_accuracy: 0.7480\n",
      "Epoch 92/150\n",
      " - 0s - loss: 0.5457 - accuracy: 0.7471 - val_loss: 0.5387 - val_accuracy: 0.7323\n",
      "Epoch 93/150\n",
      " - 0s - loss: 0.5406 - accuracy: 0.7276 - val_loss: 0.5377 - val_accuracy: 0.7402\n",
      "Epoch 94/150\n",
      " - 0s - loss: 0.5419 - accuracy: 0.7374 - val_loss: 0.5490 - val_accuracy: 0.7008\n",
      "Epoch 95/150\n",
      " - 0s - loss: 0.5442 - accuracy: 0.7354 - val_loss: 0.5370 - val_accuracy: 0.7323\n",
      "Epoch 96/150\n",
      " - 0s - loss: 0.5400 - accuracy: 0.7529 - val_loss: 0.5367 - val_accuracy: 0.7441\n",
      "Epoch 97/150\n",
      " - 0s - loss: 0.5431 - accuracy: 0.7237 - val_loss: 0.5334 - val_accuracy: 0.7402\n",
      "Epoch 98/150\n",
      " - 0s - loss: 0.5363 - accuracy: 0.7432 - val_loss: 0.5461 - val_accuracy: 0.7362\n",
      "Epoch 99/150\n",
      " - 0s - loss: 0.5408 - accuracy: 0.7432 - val_loss: 0.5464 - val_accuracy: 0.7402\n",
      "Epoch 100/150\n",
      " - 0s - loss: 0.5400 - accuracy: 0.7354 - val_loss: 0.5466 - val_accuracy: 0.7402\n",
      "Epoch 101/150\n",
      " - 0s - loss: 0.5664 - accuracy: 0.7179 - val_loss: 0.5372 - val_accuracy: 0.7480\n",
      "Epoch 102/150\n",
      " - 0s - loss: 0.5439 - accuracy: 0.7296 - val_loss: 0.5446 - val_accuracy: 0.7323\n",
      "Epoch 103/150\n",
      " - 0s - loss: 0.5416 - accuracy: 0.7354 - val_loss: 0.5299 - val_accuracy: 0.7441\n",
      "Epoch 104/150\n",
      " - 0s - loss: 0.5396 - accuracy: 0.7160 - val_loss: 0.5357 - val_accuracy: 0.7362\n",
      "Epoch 105/150\n",
      " - 0s - loss: 0.5412 - accuracy: 0.7393 - val_loss: 0.5293 - val_accuracy: 0.7520\n",
      "Epoch 106/150\n",
      " - 0s - loss: 0.5332 - accuracy: 0.7471 - val_loss: 0.5518 - val_accuracy: 0.7047\n",
      "Epoch 107/150\n",
      " - 0s - loss: 0.5292 - accuracy: 0.7432 - val_loss: 0.5397 - val_accuracy: 0.7520\n",
      "Epoch 108/150\n",
      " - 0s - loss: 0.5387 - accuracy: 0.7471 - val_loss: 0.5299 - val_accuracy: 0.7244\n",
      "Epoch 109/150\n",
      " - 0s - loss: 0.5392 - accuracy: 0.7315 - val_loss: 0.5281 - val_accuracy: 0.7598\n",
      "Epoch 110/150\n",
      " - 0s - loss: 0.5425 - accuracy: 0.7412 - val_loss: 0.5356 - val_accuracy: 0.7638\n",
      "Epoch 111/150\n",
      " - 0s - loss: 0.5351 - accuracy: 0.7490 - val_loss: 0.5301 - val_accuracy: 0.7362\n",
      "Epoch 112/150\n",
      " - 0s - loss: 0.5315 - accuracy: 0.7393 - val_loss: 0.5261 - val_accuracy: 0.7520\n",
      "Epoch 113/150\n",
      " - 0s - loss: 0.5338 - accuracy: 0.7412 - val_loss: 0.5276 - val_accuracy: 0.7480\n",
      "Epoch 114/150\n",
      " - 0s - loss: 0.5300 - accuracy: 0.7510 - val_loss: 0.5252 - val_accuracy: 0.7638\n",
      "Epoch 115/150\n",
      " - 0s - loss: 0.5350 - accuracy: 0.7335 - val_loss: 0.5247 - val_accuracy: 0.7520\n",
      "Epoch 116/150\n",
      " - 0s - loss: 0.5276 - accuracy: 0.7393 - val_loss: 0.5311 - val_accuracy: 0.7402\n",
      "Epoch 117/150\n",
      " - 0s - loss: 0.5392 - accuracy: 0.7315 - val_loss: 0.5267 - val_accuracy: 0.7795\n",
      "Epoch 118/150\n",
      " - 0s - loss: 0.5301 - accuracy: 0.7471 - val_loss: 0.5393 - val_accuracy: 0.7402\n",
      "Epoch 119/150\n",
      " - 0s - loss: 0.5353 - accuracy: 0.7451 - val_loss: 0.5464 - val_accuracy: 0.7480\n",
      "Epoch 120/150\n",
      " - 0s - loss: 0.5360 - accuracy: 0.7354 - val_loss: 0.5600 - val_accuracy: 0.6969\n",
      "Epoch 121/150\n",
      " - 0s - loss: 0.5314 - accuracy: 0.7588 - val_loss: 0.5297 - val_accuracy: 0.7638\n",
      "Epoch 122/150\n",
      " - 0s - loss: 0.5345 - accuracy: 0.7412 - val_loss: 0.5229 - val_accuracy: 0.7598\n",
      "Epoch 123/150\n",
      " - 0s - loss: 0.5305 - accuracy: 0.7257 - val_loss: 0.5230 - val_accuracy: 0.7598\n",
      "Epoch 124/150\n",
      " - 0s - loss: 0.5324 - accuracy: 0.7451 - val_loss: 0.5222 - val_accuracy: 0.7717\n",
      "Epoch 125/150\n",
      " - 0s - loss: 0.5363 - accuracy: 0.7374 - val_loss: 0.5210 - val_accuracy: 0.7638\n",
      "Epoch 126/150\n",
      " - 0s - loss: 0.5326 - accuracy: 0.7374 - val_loss: 0.5244 - val_accuracy: 0.7717\n",
      "Epoch 127/150\n",
      " - 0s - loss: 0.5286 - accuracy: 0.7335 - val_loss: 0.5196 - val_accuracy: 0.7559\n",
      "Epoch 128/150\n",
      " - 0s - loss: 0.5248 - accuracy: 0.7529 - val_loss: 0.5576 - val_accuracy: 0.7244\n",
      "Epoch 129/150\n",
      " - 0s - loss: 0.5336 - accuracy: 0.7568 - val_loss: 0.5199 - val_accuracy: 0.7638\n",
      "Epoch 130/150\n",
      " - 0s - loss: 0.5231 - accuracy: 0.7568 - val_loss: 0.5180 - val_accuracy: 0.7638\n",
      "Epoch 131/150\n",
      " - 0s - loss: 0.5281 - accuracy: 0.7393 - val_loss: 0.5206 - val_accuracy: 0.7598\n",
      "Epoch 132/150\n",
      " - 0s - loss: 0.5241 - accuracy: 0.7588 - val_loss: 0.5333 - val_accuracy: 0.7520\n",
      "Epoch 133/150\n",
      " - 0s - loss: 0.5451 - accuracy: 0.7393 - val_loss: 0.5422 - val_accuracy: 0.7402\n",
      "Epoch 134/150\n",
      " - 0s - loss: 0.5236 - accuracy: 0.7510 - val_loss: 0.5183 - val_accuracy: 0.7598\n",
      "Epoch 135/150\n",
      " - 0s - loss: 0.5293 - accuracy: 0.7354 - val_loss: 0.5231 - val_accuracy: 0.7638\n",
      "Epoch 136/150\n",
      " - 0s - loss: 0.5278 - accuracy: 0.7354 - val_loss: 0.5224 - val_accuracy: 0.7717\n",
      "Epoch 137/150\n",
      " - 0s - loss: 0.5282 - accuracy: 0.7490 - val_loss: 0.5128 - val_accuracy: 0.7638\n",
      "Epoch 138/150\n",
      " - 0s - loss: 0.5213 - accuracy: 0.7490 - val_loss: 0.5180 - val_accuracy: 0.7598\n",
      "Epoch 139/150\n",
      " - 0s - loss: 0.5252 - accuracy: 0.7432 - val_loss: 0.5128 - val_accuracy: 0.7598\n",
      "Epoch 140/150\n",
      " - 0s - loss: 0.5286 - accuracy: 0.7510 - val_loss: 0.5204 - val_accuracy: 0.7559\n",
      "Epoch 141/150\n",
      " - 0s - loss: 0.5263 - accuracy: 0.7471 - val_loss: 0.5284 - val_accuracy: 0.7559\n",
      "Epoch 142/150\n",
      " - 0s - loss: 0.5218 - accuracy: 0.7490 - val_loss: 0.5085 - val_accuracy: 0.7717\n",
      "Epoch 143/150\n",
      " - 0s - loss: 0.5241 - accuracy: 0.7451 - val_loss: 0.5116 - val_accuracy: 0.7559\n",
      "Epoch 144/150\n",
      " - 0s - loss: 0.5169 - accuracy: 0.7451 - val_loss: 0.5112 - val_accuracy: 0.7638\n",
      "Epoch 145/150\n",
      " - 0s - loss: 0.5267 - accuracy: 0.7335 - val_loss: 0.5131 - val_accuracy: 0.7598\n",
      "Epoch 146/150\n",
      " - 0s - loss: 0.5204 - accuracy: 0.7471 - val_loss: 0.5099 - val_accuracy: 0.7677\n",
      "Epoch 147/150\n",
      " - 0s - loss: 0.5163 - accuracy: 0.7510 - val_loss: 0.5046 - val_accuracy: 0.7717\n",
      "Epoch 148/150\n",
      " - 0s - loss: 0.5124 - accuracy: 0.7471 - val_loss: 0.5170 - val_accuracy: 0.7638\n",
      "Epoch 149/150\n",
      " - 0s - loss: 0.5135 - accuracy: 0.7685 - val_loss: 0.5231 - val_accuracy: 0.7598\n",
      "Epoch 150/150\n",
      " - 0s - loss: 0.5230 - accuracy: 0.7451 - val_loss: 0.5136 - val_accuracy: 0.7559\n",
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-39120e71fa00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#opção1 -ciclocompleto#ciclo_completo()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#opção 2 -ler,treinaro dataset e gravar. Depois ler o modelo e pesos e usar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0minput_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_attributes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mciclo_ler_dataset_treinar_gravar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mciclo_ler_modelo_evaluate_usar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_attributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-45b3f24a6f98>\u001b[0m in \u001b[0;36mciclo_ler_dataset_treinar_gravar\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_attributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mprint_history_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0mprint_history_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mmodel_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_attributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-45b3f24a6f98>\u001b[0m in \u001b[0;36mprint_history_accuracy\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_history_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #opção1 -ciclocompleto\n",
    "    #ciclo_completo()\n",
    "    #opção 2 -ler, treinaro dataset e gravar. Depois ler o modelo e pesos e usar\n",
    "    (input_attributes, output_attributes) = ciclo_ler_dataset_treinar_gravar()\n",
    "    ciclo_ler_modelo_evaluate_usar(input_attributes,output_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
